{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10c40472",
   "metadata": {},
   "source": [
    "# Code Snippets for assignment 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba16e48",
   "metadata": {},
   "source": [
    "1. HTML and DOM and their structure & tags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9f699e",
   "metadata": {},
   "source": [
    "• HTML (Hypertext Markup Language) is the standard markup language used to structure and present content on the World Wide Web. It consists of a series of elements (tags) that define the structure and semantics of a web page.\n",
    "• Each HTML element is enclosed within opening and closing tags, and elements can contain other elements, creating a parent-child relationship.\n",
    "• HTML is not responsible for styling or layout.\n",
    "• Some HTML tags are:\n",
    "    o\t<html>\n",
    "    o\t<head>\n",
    "    o\t<body>\n",
    "    o\t<p>\n",
    "    o\t<img>\n",
    "    o\t<a>\n",
    "    o\t<h1>, <h2>, <h3>\n",
    "    o\t<title>\n",
    "    o\t<ul>, <ol>\n",
    "    o\t<li>\n",
    "• The Document Object Model is a programming interface for web documents. It represents the structure of an HTML or XML document as a tree-like structure of objects that can be manipulated and interacted with using scripting languages like JavaScript.\n",
    "• When a web page is loaded, the browser creates a DOM representation of the HTML document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ae654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>My Webpage</title>\n",
    "</head>\n",
    "<body>\n",
    "    <header>\n",
    "        <h1>Welcome to My Webpage</h1>\n",
    "    </header>\n",
    "    <main>\n",
    "        <p>This is a paragraph.</p>\n",
    "        <a href=\"https://www.youtube.com/\">Click me</a>\n",
    "    </main>\n",
    "    <footer>\n",
    "        <p>&copy; 2023 My Webpage</p>\n",
    "    </footer>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede28d3b",
   "metadata": {},
   "source": [
    "2. CSS Selectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b41be12",
   "metadata": {},
   "source": [
    "• CSS (Cascading Style Sheets) selectors are a fundamental part of web development and are used to target and style HTML elements on a web page.\n",
    "• Few CSS Selectors are as follows:\n",
    "    o\tType Selector: p { #styles for all <p> elements. }\n",
    "    o\tClass Selector: .highlight { #styles for all elements in that class=highlight. }\n",
    "    o\tID Selector: #header { #styles for all element which the id=header. }\n",
    "    o\tDescendent Selector: div p { #styles for the all <p> which are descendent of <div>. }\n",
    "    o\tChild Selector: ul > li { #styles for all lists under unordered list. }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc17ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select by element:\n",
    "p {\n",
    "    color: blue;\n",
    "}\n",
    "\n",
    "#Select by class:\n",
    ".highlight {\n",
    "    font-weight: bold;\n",
    "}\n",
    "\n",
    "#Select by ID:\n",
    "#header {\n",
    "    background-color: yellow;\n",
    "}\n",
    "\n",
    "#Select by Descendent:\n",
    "div p {\n",
    "    color: red;\n",
    "    font-size: 16px;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310fbdc9",
   "metadata": {},
   "source": [
    "3. HTTP and request."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d426cb27",
   "metadata": {},
   "source": [
    "• Hypertext Transfer Protocol (HTTP) is a method for encoding and transporting information between a client (such as a web browser) and a web server.\n",
    "• A request is an action sent by the client and can act on the server and client in order to retrieve a specific resource, like a web page or an image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a80dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.example.com/data\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(data)\n",
    "else:\n",
    "    print(\"Request failed with status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1095be",
   "metadata": {},
   "source": [
    "4. Parsing HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b5657a",
   "metadata": {},
   "source": [
    "• Parsing HTML refers to the process of analysing and interpreting the structure and content of an HTML document.\n",
    "• Parsing is essential for web browsers, search engines, and other software to understand and display the content correctly.\n",
    "• The parsing process involves breaking down the raw HTML text into a structured format that the software can work with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff818a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"<p>This is a <strong>paragraph</strong> with <a href='https://www.example.com'>a link</a></p>\"\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "paragraph = soup.find('p')\n",
    "strong_text = paragraph.find('strong').text\n",
    "link = paragraph.find('a')['href']\n",
    "\n",
    "print(\"Paragraph:\", paragraph.text)\n",
    "print(\"Strong text:\", strong_text)\n",
    "print(\"Link:\", link)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fc17b5",
   "metadata": {},
   "source": [
    "5. Web Scrapping Ethics and Legality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dc9931",
   "metadata": {},
   "source": [
    "• Web scraping involves extracting data from websites, and its ethics and legality can be complex and depend on various factors, including the purpose of scraping, the website's terms of use, and applicable laws.\n",
    "• ETHICS:\n",
    "    o Respect for Terms of Use.\n",
    "    o Purpose of Scraping.\n",
    "    o Impact on website performance.\n",
    "    o Respect for Privacy.\n",
    "    o Attribution and Ownership: Give proper attribution to the source of the scraped data and respect copyright and intellectual property rights.\n",
    "• LEGALITY:\n",
    "    o Copywrite and Intellectual Property.\n",
    "    o Violation of Terms of Use.\n",
    "    o Publicly Available Data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47ddfed",
   "metadata": {},
   "source": [
    "6. Basics of API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30791d6",
   "metadata": {},
   "source": [
    "• An API (Application Programming Interface) is a set of rules and protocols that allows different software applications to communicate and interact with each other.\n",
    "• APIs enable developers to access certain features or data from another application, service, or platform without needing to understand the internal workings of that application.\n",
    "• Example: Websites that use “Sign in using Google.” or “Sign in using Facebook.”, they are using the data from Google or Facebook to verify the person and let the person use their website.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc43bfd5",
   "metadata": {},
   "source": [
    "7. User Agents and Headers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2e767c",
   "metadata": {},
   "source": [
    "• User Agents: A user agent is a string of text that identifies the software and device (client) that is making a request to a server, typically over the internet.\n",
    "• Headers: HTTP headers are pieces of information included in the requests and responses exchanged between a client and a server.\n",
    "• Headers are crucial for controlling the behaviour of the client and server during web communication. They facilitate efficient data transfer, authentication, and content negotiation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fed193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"My User Agent\",\n",
    "    \"Custom-Header\": \"Value\"\n",
    "}\n",
    "\n",
    "url = \"https://www.example.com\"\n",
    "response = requests.get(url, headers=headers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c19991",
   "metadata": {},
   "source": [
    "8. Dynamic Websites and AJAX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a62f60d",
   "metadata": {},
   "source": [
    "• Dynamic websites are websites that display content that can change or update dynamically without requiring a full page reload.\n",
    "• The content is generated on the server or client side based on user interactions or other events, this allows for more interactive and responsive user experiences compared to traditional static websites.\n",
    "• AJAX (Asynchronous JavaScript and XML): AJAX is a technique used to create interactive and dynamic web applications by enabling asynchronous communication between the browser and the server. It allows parts of a web page to be updated without requiring a full page reload.\n",
    "• AJAX is widely used in web development to create interactive web applications, such as social media feeds, search autosuggestions, live chat systems, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037774d8",
   "metadata": {},
   "source": [
    "9. Regular Expression (Regex)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f277d54",
   "metadata": {},
   "source": [
    "• A regular expression is a sequence of characters that defines a search pattern.\n",
    "• Regular expressions are used for pattern matching within strings, making them a powerful tool for text manipulation and data validation.\n",
    "• Regular expressions consist of a combination of normal characters (literal characters) and special characters (metacharacters) that have special meanings.\n",
    "• These metacharacters allow you to define complex patterns for searching, matching, and replacing text.\n",
    "• Example: [a-zA-z] will match any character from a to z or A to Z.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bb1794",
   "metadata": {},
   "source": [
    "10. Python Libraries: Beautiful Soup, Requests, Scrapy, Selenium, urllib3, JSON, CSV , XML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f403ab7",
   "metadata": {},
   "source": [
    "a) Beautiful Soup: A library for parsing HTML and XML documents. It provides tools for navigating and manipulating the parsed content. It's commonly used for web scraping tasks.\n",
    "\n",
    "b) Requests: A library for making HTTP requests and handling responses. It simplifies the process of sending HTTP requests and working with data from APIs or websites.\n",
    "\n",
    "c) Scrapy: A powerful web crawling framework used for extracting data from websites. It provides features for handling HTTP requests, parsing HTML/XML, and organizing scraped data.\n",
    "\n",
    "d) Selenium: A web testing library used to automate browser actions. It's often used for tasks like web scraping on websites with dynamic content that cannot be easily parsed using traditional methods.\n",
    "\n",
    "e) urllib3: A powerful HTTP client library with features like connection pooling, support for file uploads, and more. It's a lower-level alternative to requests for more advanced use cases.\n",
    "\n",
    "f) JSON: A standard format for representing structured data. The json library in Python provides functions to encode Python objects into JSON and decode JSON into Python objects.\n",
    "\n",
    "g) CSV: A format for representing tabular data. Python's built-in csv module allows you to read and write CSV files easily.\n",
    "\n",
    "h) XML: A format for representing structured data, like HTML. Python's built-in libraries (xml.etree.ElementTree or minidom) allow you to parse and manipulate XML documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45c62dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "c) scrapy startproject myproject\n",
    "   scrapy genspider myspider example.com\n",
    "   scrapy crawl myspider\n",
    "   \n",
    "d) from selenium import webdriver\n",
    "   driver = webdriver.Chrome()\n",
    "   driver.get(\"https://www.example.com\")\n",
    "   \n",
    "e) import urllib3\n",
    "   http = urllib3.PoolManager()\n",
    "   response = http.request('GET', 'https://www.example.com')\n",
    "   \n",
    "f) import json\n",
    "   data = {\"name\": \"John\", \"age\": 30}\n",
    "   json_data = json.dumps(data)\n",
    "   decoded_data = json.loads(json_data) \n",
    "   \n",
    "g) import csv\n",
    "   with open('data.csv', 'w', newline='') as csvfile:\n",
    "   csvwriter = csv.writer(csvfile)\n",
    "   csvwriter.writerow(['Name', 'Age'])\n",
    "   csvwriter.writerow(['Daniel', 21])\n",
    "   \n",
    "h) import xml.etree.ElementTree as ET\n",
    "   xml_data = \"<data><item>Value</item></data>\"\n",
    "   root = ET.fromstring(xml_data)\n",
    "   value = root.find('item').text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
